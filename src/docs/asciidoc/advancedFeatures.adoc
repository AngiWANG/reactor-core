[[advanced]]
= Advanced Features and Concepts

This chapter covers advanced features and concepts of Reactor, including the following:

* <<advanced-mutualizing-operator-usage>>
* <<reactor.hotCold>>
* <<advanced-broadcast-multiple-subscribers-connectableflux>>
* <<advanced-three-sorts-batching>>
* <<advanced-parallelizing-parralelflux>>
* <<scheduler-factory>>
* <<hooks>>
* <<context>>
* <<null-safety>>

[[advanced-mutualizing-operator-usage]]
== Mutualizing Operator Usage
From a clean-code perspective, code reuse is generally a good thing. Reactor offers a few
patterns that can help you reuse and mutualize code, notably for operators or combination
of operators that you might want to apply regularly in your codebase. If you think of a
chain of operators as a recipe, you can create a cookbook of operator recipes.

=== Using the `transform` Operator
The `transform` operator lets you encapsulate a piece of an operator chain into a
function. That function is applied to an original operator chain at assembly time to
augment it with the encapsulated operators. Doing so applies the same operations to all
the subscribers of a sequence and is basically equivalent to chaining the operators
directly. The following code shows an example:

[source,java]
----
Function<Flux<String>, Flux<String>> filterAndMap =
f -> f.filter(color -> !color.equals("orange"))
      .map(String::toUpperCase);

Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
	.doOnNext(System.out::println)
	.transform(filterAndMap)
	.subscribe(d -> System.out.println("Subscriber to Transformed MapAndFilter: "+d));
----
image::https://raw.githubusercontent.com/reactor/reactor-core/v3.0.7.RELEASE/src/docs/marble/gs-transform.png[Transform Operator : encapsulate flows]

The preceding example produces the following output:

----
blue
Subscriber to Transformed MapAndFilter: BLUE
green
Subscriber to Transformed MapAndFilter: GREEN
orange
purple
Subscriber to Transformed MapAndFilter: PURPLE
----

=== Using the `compose` Operator
The `compose` operator is similar to `transform` and also lets you encapsulate operators
in a function. The major difference is that this function is applied to the original
sequence *on a per-subscriber basis*. It means that the function can actually produce a
different operator chain for each subscription (by maintaining some state). The
following code shows an example:

[source,java]
----
AtomicInteger ai = new AtomicInteger();
Function<Flux<String>, Flux<String>> filterAndMap = f -> {
	if (ai.incrementAndGet() == 1) {
return f.filter(color -> !color.equals("orange"))
        .map(String::toUpperCase);
	}
	return f.filter(color -> !color.equals("purple"))
	        .map(String::toUpperCase);
};

Flux<String> composedFlux =
Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
    .doOnNext(System.out::println)
    .compose(filterAndMap);

composedFlux.subscribe(d -> System.out.println("Subscriber 1 to Composed MapAndFilter :"+d));
composedFlux.subscribe(d -> System.out.println("Subscriber 2 to Composed MapAndFilter: "+d));
----
image::https://raw.githubusercontent.com/reactor/reactor-core/v3.0.7.RELEASE/src/docs/marble/gs-compose.png[Compose Operator : Per Subscriber transformation]

The preceding example produces the following output:

----
blue
Subscriber 1 to Composed MapAndFilter :BLUE
green
Subscriber 1 to Composed MapAndFilter :GREEN
orange
purple
Subscriber 1 to Composed MapAndFilter :PURPLE
blue
Subscriber 2 to Composed MapAndFilter: BLUE
green
Subscriber 2 to Composed MapAndFilter: GREEN
orange
Subscriber 2 to Composed MapAndFilter: ORANGE
purple
----

[[reactor.hotCold]]
== Hot vs Cold
So far, we have considered that all `Flux` (and `Mono`) are the same: They all represent
an asynchronous sequence of data, and nothing happens before you subscribe.

Really, though, there are two broad families of publishers: *hot* and *cold*.

The description above applies to the *cold* family of publishers. They generate data anew
for each subscription. If no subscription is created, then data never gets generated.

Think of an HTTP request: Each new subscriber will trigger an HTTP call, but no call is
made if no one is interested in the result.

*Hot* publishers, on the other hand, do not depend on any number of subscribers. They
might start publishing data right away and would continue doing so whenever a new
`Subscriber` comes in (in which case said subscriber would only see new elements emitted
_after_ it subscribed). For hot publishers, _something_ does indeed happen before you
subscribe.

One example of the few hot operators in Reactor is `just`: It directly captures the value
at assembly time and replays it to anybody subscribing to it later. To re-use the HTTP
call analogy, if the captured data is the result of an HTTP call, then only one network
call is made, when instantiating _just_.

To transform `just` into a _cold_ publisher, you can use `defer`. It defers the HTTP
request in our example to subscription time (and would result in a separate network call
for each new subscription).

NOTE: Most other _hot_ publishers in Reactor extend `Processor`.

Consider two other examples. The following code shows the first example:

[source,java]
----
Flux<String> source = Flux.fromIterable(Arrays.asList("blue", "green", "orange", "purple"))
                          .doOnNext(System.out::println)
                          .filter(s -> s.startsWith("o"))
                          .map(String::toUpperCase);

source.subscribe(d -> System.out.println("Subscriber 1: "+d));
source.subscribe(d -> System.out.println("Subscriber 2: "+d));
----

This first example produces the following output:

----
blue
green
orange
Subscriber 1: ORANGE
purple
blue
green
orange
Subscriber 2: ORANGE
purple
----

image::https://raw.githubusercontent.com/reactor/reactor-core/v3.0.7.RELEASE/src/docs/marble/gs-cold.png[Replaying behavior]

Both subscribers catch all four colors, because each subscriber causes the
process defined by the operators on the `Flux` to run.

Compare the first example to the second example, shown in the following code:

[source,java]
----
UnicastProcessor<String> hotSource = UnicastProcessor.create();

Flux<String> hotFlux = hotSource.publish()
                                .autoConnect()
                                .map(String::toUpperCase);


hotFlux.subscribe(d -> System.out.println("Subscriber 1 to Hot Source: "+d));

hotSource.onNext("blue");
hotSource.onNext("green");

hotFlux.subscribe(d -> System.out.println("Subscriber 2 to Hot Source: "+d));

hotSource.onNext("orange");
hotSource.onNext("purple");
hotSource.onComplete();
----

The second example produces the following output:
----
Subscriber 1 to Hot Source: BLUE
Subscriber 1 to Hot Source: GREEN
Subscriber 1 to Hot Source: ORANGE
Subscriber 2 to Hot Source: ORANGE
Subscriber 1 to Hot Source: PURPLE
Subscriber 2 to Hot Source: PURPLE
----
image::https://raw.githubusercontent.com/reactor/reactor-core/v3.0.7.RELEASE/src/docs/marble/gs-hot.png[Broadcasting a subscription]

Subscriber 1 catches all four colors. Subscriber 2, having been created after the first
two colors were produced, catches only the last two colors. This difference accounts for
the doubling of "ORANGE" and "PURPLE" in the output. The process described by the
operators on this Flux runs regardless of when subscriptions have been attached.

[[advanced-broadcast-multiple-subscribers-connectableflux]]
== Broadcasting to Multiple Subscribers with `ConnectableFlux`
Sometimes, you want to not only defer some processing to the subscription time of one
subscriber, but you might actually want for several of them to _rendezvous_ and *then*
trigger the subscription and data generation.

This is what `ConnectableFlux` is made for. Two main patterns are covered in the `Flux`
API that return a `ConnectableFlux`: `publish` and `replay`.

* `publish` dynamically tries to respect the demand from its various subscribers, in
terms of backpressure, by forwarding these requests to the source. Most notably, if any
subscriber has a pending demand of `0`, publish *pauses* its requesting to the source.
* `replay` buffers data seen through the first subscription, up to configurable limits
(in time and buffer size). It replays the data to subsequent subscribers.

A `ConnectableFlux` offers additional methods to manage subscriptions downstream
versus subscriptions to the original source. These additional methods include the
following:

* `connect` can be called manually once you reach enough subscriptions to the flux. That
triggers the subscription to the upstream source.
* `autoConnect(n)` can do the same job automatically once `n` subscriptions have been
made.
* `refCount(n)` not only automatically tracks incoming subscriptions but also detects
when these subscriptions are cancelled. If not enough subscribers are tracked, the source
is "disconnected", causing a new subscription to the source later if additional
subscribers appear.
* `refCount(int, Duration)` adds a "grace period": Once the number of tracked subscribers
becomes too low, it waits for the `Duration` before disconnecting the source, potentially
allowing for enough new subscribers to come in and cross the connection threshold again.

Consider the following example:

[source,java]
----
Flux<Integer> source = Flux.range(1, 3)
                           .doOnSubscribe(s -> System.out.println("subscribed to source"));

ConnectableFlux<Integer> co = source.publish();

co.subscribe(System.out::println, e -> {}, () -> {});
co.subscribe(System.out::println, e -> {}, () -> {});

System.out.println("done subscribing");
Thread.sleep(500);
System.out.println("will now connect");

co.connect();
----

The preceding code produces the following output:
----
done subscribing
will now connect
subscribed to source
1
1
2
2
3
3
----

With `autoConnect`:

[source,java]
----
Flux<Integer> source = Flux.range(1, 3)
                           .doOnSubscribe(s -> System.out.println("subscribed to source"));

Flux<Integer> autoCo = source.publish().autoConnect(2);

autoCo.subscribe(System.out::println, e -> {}, () -> {});
System.out.println("subscribed first");
Thread.sleep(500);
System.out.println("subscribing second");
autoCo.subscribe(System.out::println, e -> {}, () -> {});
----

The preceding code produces the following output:
----
subscribed first
subscribing second
subscribed to source
1
1
2
2
3
3
----

[[advanced-three-sorts-batching]]
== Three Sorts of Batching
When you have lots of elements and you want to separate them into batches, you have three
broad solutions in Reactor: grouping, windowing, and buffering. These three are
conceptually close, because they redistribute a `Flux<T>` into an aggregate. Grouping and
windowing create a `Flux<Flux<T>>`, while buffering aggregates into a `Collection<T>`.

=== Grouping with `Flux<GroupedFlux<T>>`
Grouping is the act of splitting the source `Flux<T>` into multiple batches by a *key*.

The associated operator is `groupBy`.

Each group is represented as a `GroupedFlux<T>`, which lets you retrieve the key via its
`key()` method.

There is no necessary continuity in the content of the groups. Once a source element
produces a new key, the group for this key is opened and elements that match the key end
up in the group (several groups could be open at the same time).

This means that groups:

 1. Are always disjoint (a source element belongs to 1 and only 1 group).
 2. Can contain elements from different places in the original sequence.
 3. Are never empty.

[source,java]
----
StepVerifier.create(
	Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
		.groupBy(i -> i % 2 == 0 ? "even" : "odd")
		.concatMap(g -> g.defaultIfEmpty(-1) //if empty groups, show them
				.map(String::valueOf) //map to string
				.startWith(g.key())) //start with the group's key
	)
	.expectNext("odd", "1", "3", "5", "11", "13")
	.expectNext("even", "2", "4", "6", "12")
	.verifyComplete();
----

WARNING: Grouping is best suited for when you have a medium to low number of groups. The
groups must also imperatively be consumed (such as by a `flatMap`) so that `groupBy`
continues fetching data from upstream and feeding more groups. Sometimes, these two
constraints multiply and lead to hangs, such as when you have a high cardinality and the
concurrency of the `flatMap` consuming the groups is too low.

// We should provide sample code that produces this problem, to illustrate the
// anti-pattern.

=== Windowing with `Flux<Flux<T>>`
Windowing is the act of splitting the source `Flux<T>` into _windows_, by criteria of
size, time, boundary-defining predicates, or boundary-defining `Publisher`.

The associated operators are `window`, `windowTimeout`, `windowUntil`, `windowWhile`, and
`windowWhen`.

A major difference with `groupBy` is that windows are always sequential. No
more than 2 windows can be open at the same time.

They *can* overlap, though. For instance, there is a variant with `maxSize` and `skip`
parameters. The `maxSize` parameter is the number of elements after which a window
closes, and the `skip` parameter is the number of elements in the source after which a
new window is opened. So if `maxSize > skip`, a new window opens before the previous one
closes and the two windows overlap.

The following example shows overlapping windows:

[source,java]
----
StepVerifier.create(
	Flux.range(1, 10)
		.window(5, 3) //overlapping windows
		.concatMap(g -> g.defaultIfEmpty(-1)) //show empty windows as -1
	)
		.expectNext(1, 2, 3, 4, 5)
		.expectNext(4, 5, 6, 7, 8)
		.expectNext(7, 8, 9, 10)
		.expectNext(10)
		.verifyComplete();
----

NOTE: With the reverse configuration (`maxSize` < `skip`), some elements from
the source are dropped and are not part of any window.

In the case of predicate-based windowing via `windowUntil` and `windowWhile`,
having subsequent source elements that do not match the predicate can also lead
to _empty windows_, as demonstrated in the following example:

[source,java]
----
StepVerifier.create(
	Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
		.windowWhile(i -> i % 2 == 0)
		.concatMap(g -> g.defaultIfEmpty(-1))
	)
		.expectNext(-1, -1, -1) //respectively triggered by odd 1 3 5
		.expectNext(2, 4, 6) // triggered by 11
		.expectNext(12) // triggered by 13
		.expectNext(-1) // empty completion window, would have been omitted if all matched before onComplete
		.verifyComplete();
----

=== Buffering with `Flux<List<T>>`
Buffering is similar to windowing, with the following twist: instead of emitting
_windows_ (which are each a `Flux<T>`), it emits _buffers_ (which are `Collection<T>`
- by default, `List<T>`).

The operators for buffering mirror those for windowing: `buffer`, `bufferTimeout`,
`bufferUntil`, `bufferWhile`, and `bufferWhen`.

Where the corresponding windowing operator opens a window, a buffering operator creates a
new collection and start adding elements to it. Where a window closes, the buffering
operator emits the collection.

Buffering can also lead to dropping source elements or having overlapping buffers, as
shown here:

[source,java]
----
StepVerifier.create(
	Flux.range(1, 10)
		.buffer(5, 3) //overlapping buffers
	)
		.expectNext(Arrays.asList(1, 2, 3, 4, 5))
		.expectNext(Arrays.asList(4, 5, 6, 7, 8))
		.expectNext(Arrays.asList(7, 8, 9, 10))
		.expectNext(Collections.singletonList(10))
		.verifyComplete();
----

Unlike in windowing, `bufferUntil` and `bufferWhile` do not emit an empty buffer, as
shown in the following example:

[source,java]
----
StepVerifier.create(
	Flux.just(1, 3, 5, 2, 4, 6, 11, 12, 13)
		.bufferWhile(i -> i % 2 == 0)
	)
	.expectNext(Arrays.asList(2, 4, 6)) // triggered by 11
	.expectNext(Collections.singletonList(12)) // triggered by 13
	.verifyComplete();
----
[[advanced-parallelizing-parralelflux]]
== Parallelizing Work with `ParallelFlux`

With multi-core architectures being a commodity nowadays, being able to easily
parallelize work is important. Reactor helps with that by providing a special type,
`ParallelFlux`, that exposes operators that are optimized for parallelized work.

To obtain a `ParallelFlux`, you can use the `parallel()` operator on any `Flux`. *By
itself, this method does not parallelize the work*. Rather, it divides
the workload into "rails" (by default, as many rails as there are CPU cores).

In order to tell the resulting ParallelFlux where to execute each rail (and, by
extension, to execute rails in parallel) you have to use `runOn(Scheduler)`. Note that
there is a recommended dedicated Scheduler for parallel work: `Schedulers.parallel()`.

Compare the next two examples, the first of which is shown in the following code:

[source,java]
----
Flux.range(1, 10)
    .parallel(2) //<1>
    .subscribe(i -> System.out.println(Thread.currentThread().getName() + " -> " + i));
----
<1> We force a number of rails instead of relying on the number of CPU cores.

The following code shows the second example:

[source,java]
----
Flux.range(1, 10)
    .parallel(2)
    .runOn(Schedulers.parallel())
    .subscribe(i -> System.out.println(Thread.currentThread().getName() + " -> " + i));
----

The first example produces the following output:
----
main -> 1
main -> 2
main -> 3
main -> 4
main -> 5
main -> 6
main -> 7
main -> 8
main -> 9
main -> 10
----

The second correctly parallelizes on two threads, as shown in the following output:
----
parallel-1 -> 1
parallel-2 -> 2
parallel-1 -> 3
parallel-2 -> 4
parallel-1 -> 5
parallel-2 -> 6
parallel-1 -> 7
parallel-1 -> 9
parallel-2 -> 8
parallel-2 -> 10
----

If, once you process your sequence in parallel, you want to revert back to a "normal"
`Flux` and apply the rest of the operator chain in a sequential manner, you can use the
`sequential()` method on `ParallelFlux`.

Note that `sequential()` is implicitly applied if you `subscribe` to the ParallelFlux
with a `Subscriber` but not when using the lambda-based variants of `subscribe`.

Note also that `subscribe(Subscriber<T>)` merges all the rails, while
`subscribe(Consumer<T>)` runs all the rails. If the `subscribe()` method has a lambda,
each lambda is executed as many times as there are rails.

You can also access individual rails or "groups" as a `Flux<GroupedFlux<T>>` through the
`groups()` method and apply additional operators to them through the `composeGroup()`
method.

[[scheduler-factory]]
== Replacing Default `Schedulers`
As we have seen in the <<schedulers>> section, Reactor Core comes with several
`Scheduler` implementations. While you can always create new instances through the `new*`
factory methods, each `Scheduler` flavor also has a default singleton instance that is
accessible through the direct factory method (such as `Schedulers.elastic()` versus
`Schedulers.newElastic()`).

These default instances are the ones used by operators that need a `Scheduler` to work
when you do not explicitly specify one. For example, `Flux#delayElements(Duration)` uses
the `Schedulers.parallel()` instance.

In some cases, however, you might need to change these default instances with something
else in a cross-cutting way, without having to make sure every single operator you call
has your specific `Scheduler` as a parameter. An example is measuring the time every
single scheduled task takes by wrapping the real schedulers, for instrumentation
purposes. In other words, you might want to *change the default `Schedulers`*.

Changing the default schedulers is possible through the `Schedulers.Factory` class. By
default, a `Factory` creates all the standard `Scheduler` through similarly named
methods. Each of these can be overridden with your custom implementation.

Additionally, the `Factory` exposes one additional customization method:
`decorateExecutorService`. It is invoked during the creation of every reactor-core
`Scheduler` that is backed by a `ScheduledExecutorService` (even non-default instances,
such as those created by calls to `Schedulers.newParallel()`).

This lets you tune the `ScheduledExecutorService` to be used: The default one is exposed
as a `Supplier` and, depending on the type of `Scheduler` being configured, you can choose
to entirely bypass that supplier and return your own instance or you can `get()` the
default instance and wrap it.

IMPORTANT: Once you create a `Factory` that fits your needs, you must install it via
`Schedulers.setFactory(Factory)`.

Finally, there is a last customizable hook in `Schedulers`: `onHandleError`. This hook is
invoked whenever a `Runnable` task submitted to a `Scheduler` throws an `Exception` (note
that if there is an `UncaughtExceptionHandler` set for the `Thread` that ran the task,
both the handler and the hook will be invoked).

[[hooks]]
== Using Global Hooks
Reactor has another category of configurable callbacks that are invoked by Reactor
operators in various situations. They are all set in the `Hooks` class, and fall into
three categories:

* <<hooks-dropping>>
* <<hooks-internal>>
* <<hooks-assembly>>

[[hooks-dropping]]
=== Dropping Hooks
Dropping hooks are invoked when the source of an operator does not comply with the
Reactive Streams specification. These kind of errors are outside of the normal execution
path (that is, they cannot be propagated through `onError`).

Typically, a `Publisher` calls `onNext` on the operator despite having already called
`onCompleted` on it previously. In that case, the `onNext` value is _dropped_. The same
is true for an extraneous `onError` signal.

The corresponding hooks, `onNextDropped` and `onErrorDropped`, let you provide a global
`Consumer` for these drops. For example, you can use it to log the drop and cleanup
resources associated with a value if needed (as it never makes it to the rest of the
reactive chain).

Setting the hooks twice in a row is additive: every consumer you provide is invoked. The
hooks can be fully reset to their defaults by using `Hooks.resetOn*Dropped()` methods.

[[hooks-internal]]
=== Internal Error Hook
One hook, `onOperatorError`, is invoked by operators when an unexpected `Exception` is
thrown during the execution of their `onNext`, `onError` and `onComplete` methods.

Unlike the previous category, this is still within the normal execution path. A typical
example is the `map` operator with a map function that throws an `Exception` (such as
division by zero). It is still possible at this point to go through the usual channel of
`onError`, and that is what the operator does.

First, it passes the `Exception` through `onOperatorError`. The hook lets you inspect the
error (and the incriminating value, if relevant) and _change_ the `Exception`. Of course,
you can also do something on the side, such as log and return the original Exception.

Note that the `onOperatorError` hook can be set multiple times: you can provide a
`String` identifier for a particular `BiFunction`, and subsequent calls with different
keys concatenates the functions, which are all executed. On the other hand, reusing the
same key twice lets you replace a function you previously set.

As a consequence, the default hook behavior can be both fully reset (using
`Hooks.resetOnOperatorError()`) or partially reset for a specific `key` only (by using
`Hooks.resetOnOperatorError(String)`).

[[hooks-assembly]]
=== Assembly Hooks
These hooks tie in the lifecycle of operators. They are invoked when a chain of operators
is assembled (that is, instantiated). `onEachOperator` lets you dynamically change each
operator as it is assembled in the chain, by returning a different `Publisher`.
`onLastOperator` is similar, except that it is only invoked on the last operator in the
chain before the `subscribe` call.

Like `onOperatorError`, these hooks are cumulative and can be identified with a key. They
can also be reset partially or totally.

=== Hook Presets
The `Hooks` utility class provides a couple of preset hooks. These are alternatives to
the default behaviors that you can use by calling their corresponding method, rather than
coming up with the hook yourself:

* `onNextDroppedFail()`: `onNextDropped` used to throw a `Exceptions.failWithCancel()`
exception. It now defaults to logging the dropped value at the DEBUG level. To go back to
the old default behavior of throwing, use `onNextDroppedFail()`.

* `onOperatorDebug()`: This method activates <<debug-activate,debug mode>>. It ties into
the `onOperatorError` hook, so calling `resetOnOperatorError()` also resets it. It can be
independently reset via `resetOnOperatorDebug()` as it uses a specific key internally.

[[context]]
== 增加一个 Context 到响应式序列
当从命令式编程风格切换到响应式编程风格的时候，一个技术上最大的挑战就是线程处理。

与习惯做法不同的是，在响应式编程中，一个线程（`Thread`）可以被用于处理多个同时运行的异步序列
（实际上是非阻塞的）。执行过程也会经常从一个线程切换到另一个线程。

这样的情况下，对于开发者来说，如果依赖线程模型中相对“稳定”的特性——比如 `ThreadLocal`
——就会变得很难。因为它会让你将数据绑定到一个 *线程* 上，所以在响应式环境中使用就变得
比较困难。因此，将使用了 `ThreadLocal` 的库应用于 Reactor 的时候就会带来新的挑战。通常会更糟，
它用起来效果会更差，甚至会失败。 比如，使用 Logback 的 MDC 来存储日志相关的 ID，就是一个非常符合
这种情况的例子。

通常的对 `ThreadLocal` 的替代方案是将环境相关的数据 `C`，同业务数据 `T` 一起置于序列中,
比如使用 `Tuple2<T, C>`。这种方案看起来并不好，况且会在方法和 `Flux` 泛型中暴露环境数据信息。

自从版本 `3.1.0`，Reactor 引入了一个类似于 `ThreadLocal` 的高级功能：`Context`。它作用于一个
`Flux` 或一个 `Mono` 上，而不是应用于一个线程（`Thread`）。

为了说明，这里有个读写 `Context` 的简单例子：
[source,java]
----
String key = "message";
Mono<String> r = Mono.just("Hello")
                .flatMap( s -> Mono.subscriberContext()
                                   .map( ctx -> s + " " + ctx.get(key)))
                .subscriberContext(ctx -> ctx.put(key, "World"));

StepVerifier.create(r)
            .expectNext("Hello World")
            .verifyComplete();
----

接下来的几个小节，我们来了解 `Context` 是什么以及如何用，从而最终可以理解上边的例子。

IMPORTANT: 这是一个主要面向库开发人员的高级功能。这需要开发者对 `Subscription` 的生命周期
充分理解，并且明白它主要用于 subscription 相关的库。

=== `Context` API
`Context` 是一个类似于 `Map`（这种数据结构）的接口：它存储键值（key-value）对，你需要通过 key 来获取值：

* key 和 value 都是 `Object` 类型，所以 `Context` 可以包含任意数量的任意对象。
* `Context` 是 *不可变的（immutable）*。
* 用 `put(Object key, Object value)` 方法来存储一个键值对，返回一个新的 `Context` 对象。
你也可以用 `putAll(Context)` 方法将两个 context 合并为一个新的 context。
* 用 `hasKey(Object key)` 方法检查一个 key 是否已经存在。
* 用 `getOrDefault(Object key, T defaultValue)` 方法取回 key 对应的值（类型转换为 `T`），
或在找不到这个 key 的情况下返回一个默认值。
* 用 `getOrEmpty(Object key)` 来得到一个 `Optional<T>` （context 会尝试将值转换为 `T`）。
* 用 `delete(Object key)` 来删除 key 关联的值，并返回一个新的 `Context`。

TIP: *创建一个* `Context` 时，你可以用静态方法 `Context.of` 预先存储最多 5 个键值对。
它接受 2, 4, 6, 8 或 10 个 `Object` 对象，两两一对作为键值对添加到 `Context`。 +
 +
你也可以用 `Context.empty()` 方法来创建一个空的 `Context`。

=== 把 `Context` 绑定到 `Flux` and Writing
为了使用 context，它必须要绑定到一个指定的序列，并且链上的每个 operator 都可以访问它。
注意，这里的 operator 必须是 Reactor 内置的 operator，因为 `Context` 是 Reactor 特有的。

实际上，一个 `Context` 是绑定到每一个链中的 `Subscriber` 上的。 它使用 `Subscription`
的传播机制来让自己对每一个 operator 都可见（从最后一个 `subscribe` 沿链向上）。

为了填充 `Context` ——只能在订阅时（subscription time）——你需要使用 `subscriberContext` operator。

`subscriberContext(Context)` 方法会将你提供的 `Context` 与来自下游（记住，`Context` 是从下游
向上游传播的）的 `Context`合并。 这通过调用 `putAll` 实现，最后会生成一个新的 `Context` 给上游。

TIP: 你也可以用更高级的 `subscriberContext(Function<Context, Context>)`。它接受来自下游的
`Context`，然后你可以根据需要添加或删除值，然后返回新的 `Context`。你甚至可以返回一个完全不同
的对象，虽然不太建议这样（这样可能影响到依赖这个 `Context` 的库）。

=== 读取 Context
填充 `Context` 是一方面，读取数据同样重要。多数时候，添加内容到 `Context` 是最终用户的责任，
但是利用这些信息是库的责任，因为库通常是客户代码的上游。

读取 context 数据使用静态方法 `Mono.subscriberContext()`。

=== 简单的例子
本例的初衷是为了让你对如何使用 `Context` 有个更好的理解。

让我们先回头看一下最初的例子：

[source,java]
----
String key = "message";
Mono<String> r = Mono.just("Hello")
                .flatMap( s -> Mono.subscriberContext() //<2>
                                   .map( ctx -> s + " " + ctx.get(key))) //<3>
                .subscriberContext(ctx -> ctx.put(key, "World")); //<1>

StepVerifier.create(r)
            .expectNext("Hello World") //<4>
            .verifyComplete();
----
<1> operator 链以调用 `subscriberContext(Function)` 结尾，将 `"World"` 作为 `"message"` 这个
key 的 值添加到 `Context` 中。
<2> 对源调用 `flatMap` 用 `Mono.subscriberContext()` 方法拿到 `Context`。
<3> 然后使用 `map` 读取关联到 `"message"` 的值，然后与原来的值连接。
<4> 最后 `Mono<String>` 确实发出了 `"Hello World"`。

IMPORTANT: 上边的数字顺序并不是按照代码行顺序排的，这并非错误：它代表了执行顺序。虽然
`subscriberContext` 是链上的最后一个环节，但确实最先执行的（原因在于 subscription 信号
是从下游向上的）。

注意在你的 operator 链中，**写入** 与 **读取** `Context` 的 **相对位置** 很重要：因为
`Context` 是不可变的，它的内容只能被上游的 operator 看到，如下例所示：

[source,java]
----
String key = "message";
Mono<String> r = Mono.just("Hello")
                     .subscriberContext(ctx -> ctx.put(key, "World")) //<1>
                     .flatMap( s -> Mono.subscriberContext()
                                        .map( ctx -> s + " " + ctx.getOrDefault(key, "Stranger")));  //<2>

StepVerifier.create(r)
            .expectNext("Hello Stranger") //<3>
            .verifyComplete();
----
<1> 写入 `Context` 的位置太靠上了...
<2> 所以在 `flatMap` 就没有 key 关联的值，使用了默认值。
<3> 结果 `Mono<String>` 发出了 `"Hello Stranger"`。

下面的例子同样说明了 `Context` 的不可变性（`Mono.subscriberContext()` 总是返回由 `subscriberContext` 配置的 `Context`）：

[source,java]
----
String key = "message";

Mono<String> r = Mono.subscriberContext() // <1>
	.map( ctx -> ctx.put(key, "Hello")) // <2>
	.flatMap( ctx -> Mono.subscriberContext()) // <3>
	.map( ctx -> ctx.getOrDefault(key,"Default")); // <4>

StepVerifier.create(r)
	.expectNext("Default") // <5>
	.verifyComplete();
----
<1> 拿到 `Context`。
<2> 在 `map` 方法中我们尝试修改它。
<3> 在 `flatMap` 中再次获取 `Context`。
<4> 读取 `Context` 中可能的值。
<5> 值从来没有被设置为 `"Hello"`。

类似的，如果多次对 `Context` 中的同一个 key 赋值的话，要看 **写入的相对顺序** ：
读取 `Context` 的 operator 只能拿到下游最近的一次写入的值，如下例所示：

[source,java]
----
String key = "message";
Mono<String> r = Mono.just("Hello")
                .flatMap( s -> Mono.subscriberContext()
                                   .map( ctx -> s + " " + ctx.get(key)))
                .subscriberContext(ctx -> ctx.put(key, "Reactor")) //<1>
                .subscriberContext(ctx -> ctx.put(key, "World")); //<2>

StepVerifier.create(r)
            .expectNext("Hello Reactor") //<3>
            .verifyComplete();
----
<1> 写入 `"message"` 的值。
<2> 另一次写入 `"message"` 的值。
<3> `map` 方法值能拿到下游最近的一次写入的值： `"Reactor"`。

这里，首先 `Context` 中的 key 被赋值 `"World"`。然后订阅信号（subscription signal）向上游
移动，又发生了另一次写入。这次生成了第二个不变的 `Context`，里边的值是 `"Reactor"`。之后，
数据开始流动， `flatMap` 拿到最近的 `Context` ，也就是第二个值为 `Reactor` 的 `Context`。

你可能会觉得 `Context` 是与数据信号一块传播的。如果是那样的话，在两次写入操作中间加入的一个
`flatMap` 会使用最上游的这个 `Context`。但并不是这样的，如下：

[source,java]
----
String key = "message";
Mono<String> r = Mono.just("Hello")
                     .flatMap( s -> Mono.subscriberContext()
                                        .map( ctx -> s + " " + ctx.get(key))) //<3>
                     .subscriberContext(ctx -> ctx.put(key, "Reactor")) //<2>
                     .flatMap( s -> Mono.subscriberContext()
                                        .map( ctx -> s + " " + ctx.get(key))) //<4>
                     .subscriberContext(ctx -> ctx.put(key, "World")); //<1>

StepVerifier.create(r)
            .expectNext("Hello Reactor World") //<5>
            .verifyComplete();
----
<1> 这里是第一次赋值。
<2> 这里是第二次赋值。
<3> 第一个 `flatMap` 看到的是第二次的赋值。
<4> 第二个 `flatMap` 将上一个的结果与 **第一次赋值** 的 context 值连接。
<5> `Mono` 发出的是 `"Hello Reactor World"`。

原因在于 `Context` 是与 `Subscriber` 关联的，而每一个 operator 访问的 `Context`
来自其下游的 `Subscriber`。

最后一个有意思的传播方式是，对 `Context` 的赋值也可以在一个 `flatMap` **内部**，如下：

[source,java]
----
String key = "message";
Mono<String> r =
        Mono.just("Hello")
            .flatMap( s -> Mono.subscriberContext()
                               .map( ctx -> s + " " + ctx.get(key))
            )
            .flatMap( s -> Mono.subscriberContext()
                               .map( ctx -> s + " " + ctx.get(key))
                               .subscriberContext(ctx -> ctx.put(key, "Reactor")) //<1>
            )
            .subscriberContext(ctx -> ctx.put(key, "World")); // <2>

StepVerifier.create(r)
            .expectNext("Hello World Reactor")
            .verifyComplete();
----
<1> 这个 `subscriberContext` 不会影响所在 `flatMap` 之外的任何东西。
<2> 这个 `subscriberContext` 会影响主序列的 `Context`。

上边的例子中，最后发出的值是 `"Hello World Reactor"` 而不是 "Hello Reactor World"，因为赋值
"Reactor" 的 `subscriberContext` 是作用于第二个 `flatMap` 的内部序列的。所以不会在主序列可见/
传播，第一个 `flatMap` 也看不到它。传播（Propagation） + 不可变性（immutability）将类似
`flatMap` 这样的 operator 中的创建的内部序列中的 `Context` 与外部隔离开来。

=== 完整的例子
让我们来看一个实际的从 `Context` 中读取值的例子：一个响应式的 HTTP 客户端将一个 `Mono<String>`
（用于 `PUT` 请求）作为数据源，同时通过一个特定的 key 使用 Context 将相关的ID信息放入请求头中。

从用户角度，是这样调用的：

[source,java]
----
doPut("www.example.com", Mono.just("Walter"))
----

为了传播一个相关ID，应该这样调用：

[source,java]
----
doPut("www.example.com", Mono.just("Walter"))
	.subscriberContext(Context.of(HTTP_CORRELATION_ID, "2-j3r9afaf92j-afkaf"))
----

由上可见，用户代码使用了 `subscriberContext` 来为 `Context` 的 `HTTP_CORRELATION_ID`
赋值。上游的 operator 是一个由 HTTP 客户端库返回的 `Mono<Tuple2<Integer, String>>`
（一个简化的 HTTP 响应）。所以能够正确将信息从用户代码传递给库代码。

下边的例子演示了从库的角度由 context 读取值的模拟代码，如果能够找到相关ID，则“增加请求”：

[source,java]
----
static final String HTTP_CORRELATION_ID = "reactive.http.library.correlationId";

Mono<Tuple2<Integer, String>> doPut(String url, Mono<String> data) {
	Mono<Tuple2<String, Optional<Object>>> dataAndContext =
			data.zipWith(Mono.subscriberContext() // <1>
			                 .map(c -> c.getOrEmpty(HTTP_CORRELATION_ID))); // <2>

	return dataAndContext
			.<String>handle((dac, sink) -> {
				if (dac.getT2().isPresent()) { // <3>
					sink.next("PUT <" + dac.getT1() + "> sent to " + url + " with header X-Correlation-ID = " + dac.getT2().get());
				}
				else {
					sink.next("PUT <" + dac.getT1() + "> sent to " + url);
				}
				sink.complete();
			})
			.map(msg -> Tuples.of(200, msg));
}
----
<1> 用 `Mono.subscriberContext()` 拿到 `Context`。
<2> 提取出相关ID的值——是一个 `Optional`。
<3> 如果值存在，那么就将其加入请求头。

在这段库代码片段中，你可以看到它是如何将 `Mono` 和 `Mono.subscriberContext()` zip 起来的。
返回的是一个 `Tuple2<String, Context>`，这个 `Context` 包含来自下游的 `HTTP_CORRELATION_ID`
的值。

库代码接着用 `map` 读取出那个 key 的值 `Optional<String>`，如果值存在，将其作为 `X-Correlation-ID` 请求头。
最后一块而用 `handle` 来处理。

用来验证上边的库代码的测试程序如下：

[source,java]
----
@Test
public void contextForLibraryReactivePut() {
	Mono<String> put = doPut("www.example.com", Mono.just("Walter"))
			.subscriberContext(Context.of(HTTP_CORRELATION_ID, "2-j3r9afaf92j-afkaf"))
			.filter(t -> t.getT1() < 300)
			.map(Tuple2::getT2);

	StepVerifier.create(put)
	            .expectNext("PUT <Walter> sent to www.example.com with header X-Correlation-ID = 2-j3r9afaf92j-afkaf")
	            .verifyComplete();
}
----

[[null-safety]]
== Null-safety

Although Java does not allow expressing null-safety with its type system, Reactor
now provides annotations to declare nullability of APIs, similar to those provided by
Spring Framework 5.

Reactor leverages these annotations, but they can also be used in any Reactor-based
Java project to declare null-safe APIs. Nullability of types used inside method bodies
is outside of the scope of this feature.

These annotations are meta-annotated with https://jcp.org/en/jsr/detail?id=305[JSR 305]
annotations (a dormant JSR that is supported by tools like IntelliJ IDEA) to provide
useful warnings to Java developers related to null-safety in order to avoid
`NullPointerException` at runtime. JSR 305 meta-annotations allows tooling vendors to
provide null-safety support in a generic way, without having to hard-code support for Reactor annotations.

[NOTE]
====
It is not necessary nor recommended with Kotlin 1.1.5+ to have a dependency on JSR 305 in
your project classpath.
====

They are also used by Kotlin which natively supports
https://kotlinlang.org/docs/reference/null-safety.html[null-safety]. See
<<kotlin-null-safety,this dedicated section>> for more details.

The following annotations are provided in the `reactor.util.annotation` package:

* https://projectreactor.io/docs/core/release/api/reactor/util/annotation/NonNull.html[`@NonNull`]
indicates that a specific parameter, return value, or field cannot be `null`.
(It is not needed on parameters and return value where `@NonNullApi` applies) .
* https://projectreactor.io/docs/core/release/api/reactor/util/annotation/Nullable.html[`@Nullable`]
indicates that a parameter, return value, or field can be `null`.
* https://projectreactor.io/docs/core/release/api/reactor/util/annotation/NonNullApi.html[`@NonNullApi`]
is a package level annotation that indicates non-null is the default behavior for
parameters and return values.

[NOTE]
====
Nullability for generic type arguments, varargs, and array elements is not supported yet.
See https://github.com/reactor/reactor-core/issues/878[issue #878] for up-to-date
information.
====
